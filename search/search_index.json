{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#documentation","title":"Documentation","text":"<p>Documentation for quick_draw</p>"},{"location":"my_api/","title":"QuickDraw Model Documentation","text":""},{"location":"my_api/#model-overview","title":"Model Overview","text":"<p>The QuickDraw image classification model is derived from the PyTorch package TIMM with pretrained models.  Our chosen model is the 'tf_efficientnet_lite0'-model, which is loaded through the code below. </p> <p>               Bases: <code>Module</code></p> <p>\" A model for Quick, Draw! dataset using EfficientNet-lite0 as the base model. It replaces the classifier layer to match the number of classes in our example.</p> Source code in <code>src/quick_draw/model.py</code> <pre><code>class QuickDrawModel(nn.Module):\n    \"\"\"\"\n    A model for Quick, Draw! dataset using EfficientNet-lite0 as the base model.\n    It replaces the classifier layer to match the number of classes in our example.\n    \"\"\"\n    def __init__(self, num_classes=10):  # Adjust num_classes \n        super(QuickDrawModel, self).__init__()\n\n        # Load a pre-trained timm model (EfficientNet-lite0)\n        self.base_model = timm.create_model('tf_efficientnet_lite0', pretrained=True, in_chans=1)  # in_chans=1 for grayscale input\n\n        # Replace the classifier to match the number of classes in Quick, Draw!\n        in_features = self.base_model.classifier.in_features\n        self.base_model.classifier = nn.Linear(in_features, num_classes)\n\n        # Freeze the base model parameters (all layers except the classifier)\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n\n        # Unfreeze the classifier layer so it can be trained\n        for param in self.base_model.classifier.parameters():\n            param.requires_grad = True\n\n\n    def forward(self, x):\n        return self.base_model(x)\n</code></pre>"},{"location":"my_api/#training-process","title":"Training Process","text":"<p>After loading the model, it is trained on 100 images from each of the 10 selected classes. The code for the training process and the associated hyperparameters can be seen in below. </p>"},{"location":"my_api/#training-functions","title":"Training Functions","text":""},{"location":"my_api/#src.quick_draw.train_wandb.train","title":"train","text":"<pre><code>train(\n    lr: float = 0.001,\n    batch_size: int = 32,\n    epochs: int = 1,\n    gcp_bucket: bool = False,\n    secret_manager: bool = False,\n) -&gt; None\n</code></pre> <p>Train a model on the 'Quick, Draw!' dataset with validation.</p> <pre><code>lr (float): The learning rate of the optimizer.\nbatch_size (int): The batch size for training.\nepochs (int): The number of epochs to train for.\ngcp_bucket (bool): Whether to save the model to a GCP bucket.\nsecret_manager (bool): Whether to use the secret manager.\n</code></pre> <pre><code>None\n</code></pre>"},{"location":"my_api/#src.quick_draw.train_wandb.train--saves","title":"Saves:","text":"<pre><code>quickdraw_model.pth: The trained model.\ntraining_and_validation_statistics.png: A plot of the training and validation statistics.\n</code></pre>"},{"location":"my_api/#src.quick_draw.train_wandb.train--wandb","title":"WandB:","text":"<pre><code>Logs the training and validation statistics\n</code></pre> Source code in <code>src/quick_draw/train_wandb.py</code> <pre><code>def train(lr: float = 1e-3, batch_size: int = 32, epochs: int = 1, gcp_bucket: bool = False, secret_manager: bool = False) -&gt; None:\n    \"\"\"\n    Train a model on the 'Quick, Draw!' dataset with validation.\n\n    Args:\n    -----\n        lr (float): The learning rate of the optimizer.\n        batch_size (int): The batch size for training.\n        epochs (int): The number of epochs to train for.\n        gcp_bucket (bool): Whether to save the model to a GCP bucket.\n        secret_manager (bool): Whether to use the secret manager.\n\n    Returns:\n    --------\n        None\n\n    Saves:\n    ------\n        quickdraw_model.pth: The trained model.\n        training_and_validation_statistics.png: A plot of the training and validation statistics.\n    WandB:\n    ------\n        Logs the training and validation statistics\n    \"\"\"\n    print(\"Training day and night\")\n    print(f\"{lr=}, {batch_size=}, {epochs=}\")\n    print(os.getcwd())\n    print(os.listdir())\n\n    if secret_manager:\n        wandb.login(key=\"4359ea2ef73a2790826a8f0b8fad581d23ca3b68\")\n\n    # Initialize wandb\n    run = wandb.init(\n        project=\"train_wandb\",\n        config={\"lr\": lr, \"batch_size\": batch_size, \"epochs\": epochs},\n    )\n\n    # Load datasets using train_function() and validation_function()\n    train_set = load_dataset('train', gcp_bucket)\n    validation_set = load_dataset('val', gcp_bucket)\n\n    # Create DataLoaders\n    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n    validation_dataloader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size)\n\n    # Initialize the model, loss function, and optimizer\n    model = QuickDrawModel().to(DEVICE)\n    loss_fn = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    # Track statistics\n    statistics = {\"train_loss\": [], \"train_accuracy\": [], \"val_loss\": [], \"val_accuracy\": []}\n\n    for epoch in tqdm(range(epochs)):\n        print(epoch)\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n\n        # Training Loop\n        for i, (images, labels) in enumerate(train_dataloader):\n            print(i)\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n            train_total += labels.size(0)\n\n        train_loss /= len(train_dataloader)\n        train_accuracy = train_correct / train_total\n        statistics[\"train_loss\"].append(train_loss)\n        statistics[\"train_accuracy\"].append(train_accuracy)\n\n        # Validation Loop\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for images, labels in validation_dataloader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                loss = loss_fn(outputs, labels)\n\n                val_loss += loss.item()\n                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n                val_total += labels.size(0)\n\n        val_loss /= len(validation_dataloader)\n        val_accuracy = val_correct / val_total\n        statistics[\"val_loss\"].append(val_loss)\n        statistics[\"val_accuracy\"].append(val_accuracy)\n\n        # Log statistics on wandb\n        wandb.log({\"train_loss\": train_loss, \n                   \"train_accuracy\": train_accuracy, \n                   \"val_loss\": val_loss, \n                   \"val_accuracy\": val_accuracy})\n\n        print(f\"Epoch {epoch+1}/{epochs}, \"\n              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n\n    # Save model on wandb\n    artifact = wandb.Artifact(\n            name=\"efficient_net\",\n            type=\"model\",\n            description=f\"Run: {wandb.run.id}\"\n        )\n    # Save model\n    print(\"Training complete\")\n    if gcp_bucket:\n        torch.save(model.state_dict(), \"/gcs/quickdraw-databucket/models/quickdraw_model.pth\")\n        artifact.add_file(\"/gcs/quickdraw-databucket/models/quickdraw_model.pth\")\n    else:\n        torch.save(model.state_dict(), \"models/quickdraw_model.pth\")\n        artifact.add_file(\"models/quickdraw_model.pth\")\n\n    wandb.log_artifact(artifact)\n\n    # Plot training and validation statistics\n    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n    axs[0].plot(statistics[\"train_loss\"], label=\"Train Loss\", color=\"blue\")\n    axs[0].plot(statistics[\"val_loss\"], label=\"Val Loss\", color=\"orange\")\n    axs[0].set_title(\"Loss\")\n    axs[0].legend()\n\n    axs[1].plot(statistics[\"train_accuracy\"], label=\"Train Accuracy\", color=\"blue\")\n    axs[1].plot(statistics[\"val_accuracy\"], label=\"Val Accuracy\", color=\"orange\")\n    axs[1].set_title(\"Accuracy\")\n    axs[1].legend()\n\n    figure_path = 'reports/figures/training_and_validation_statistics.png'\n    fig.savefig(figure_path)\n    wandb.log({f\"training_and_validation_statistics\": wandb.Image(figure_path)})\n</code></pre>"}]}